var documenterSearchIndex = {"docs":
[{"location":"fine-tuneFPS/#Advanced-usage-of-FletcherPenaltyNLPSolver","page":"Fine-tune FPS","title":"Advanced usage of FletcherPenaltyNLPSolver","text":"","category":"section"},{"location":"fine-tuneFPS/#Contents","page":"Fine-tune FPS","title":"Contents","text":"","category":"section"},{"location":"fine-tuneFPS/","page":"Fine-tune FPS","title":"Fine-tune FPS","text":"Pages = [\"fine-tuneFPS.md\"]","category":"page"},{"location":"fine-tuneFPS/","page":"Fine-tune FPS","title":"Fine-tune FPS","text":"The main function exported by this package is the function fps_solve whose basic usage has been illustrated previously. It is also possible to fine-tune the parameters used in the implementation in two different ways.","category":"page"},{"location":"fine-tuneFPS/#Examples","page":"Fine-tune FPS","title":"Examples","text":"","category":"section"},{"location":"fine-tuneFPS/","page":"Fine-tune FPS","title":"Fine-tune FPS","text":"FletcherPenaltyNLPSolver exports the function fps_solve:","category":"page"},{"location":"fine-tuneFPS/","page":"Fine-tune FPS","title":"Fine-tune FPS","text":"   fps_solve(nlp::AbstractNLPModel, x0::AbstractVector{T} = nlp.meta.x0; subsolver_verbose::Int = 0, lagrange_bound = 1 / sqrt(eps(T)), kwargs...)\n   fps_solve(stp::NLPStopping; subsolver_verbose::Int = 0, lagrange_bound = 1 / sqrt(eps()), kwargs...)\n   fps_solve(stp::NLPStopping, fpssolver::FPSSSolver{T, QDS, US}; subsolver_verbose::Int = 0, lagrange_bound::T = 1 / sqrt(eps(T)))","category":"page"},{"location":"fine-tuneFPS/","page":"Fine-tune FPS","title":"Fine-tune FPS","text":"It is, therefore, possible to either call fps_solve(nlp, x, kwargs...) and the keywords arguments are passed to both NLPStopping and/or FPSSSolver constructor or build an instance of NLPStopping and/or FPSSSolver directly.","category":"page"},{"location":"fine-tuneFPS/","page":"Fine-tune FPS","title":"Fine-tune FPS","text":"using ADNLPModels, FletcherPenaltyNLPSolver\n\nnlp = ADNLPModel(\n  x -> 100 * (x[2] - x[1]^2)^2 + (x[1] - 1)^2, \n  [-1.2; 1.0],\n  x->[x[1] * x[2] - 1], \n  [0.0], [0.0],\n  name = \"Rosenbrock with x₁x₂=1\"\n)\nstats = fps_solve(nlp)","category":"page"},{"location":"fine-tuneFPS/","page":"Fine-tune FPS","title":"Fine-tune FPS","text":"The alternative using NLPStopping, see Stopping.jl, allow to reuse the same memory if one would re-solve a problem of the same dimension","category":"page"},{"location":"fine-tuneFPS/","page":"Fine-tune FPS","title":"Fine-tune FPS","text":"using ADNLPModels, FletcherPenaltyNLPSolver, Stopping\nstp = NLPStopping(nlp)\nstats = fps_solve(stp)\nstp.current_state.x .= rand(2)\nstats = fps_solve(stp)","category":"page"},{"location":"fine-tuneFPS/","page":"Fine-tune FPS","title":"Fine-tune FPS","text":"The FPSSSolver, see FPSSSolver, contains all the metadata and additional pre-allocated memory used by the algorithm.","category":"page"},{"location":"fine-tuneFPS/","page":"Fine-tune FPS","title":"Fine-tune FPS","text":"stp = NLPStopping(nlp)\ndata = FPSSSolver(nlp, zero(Float64); kwargs...)\nstats = fps_solve(stp, data)","category":"page"},{"location":"fine-tuneFPS/#List-of-possible-options","page":"Fine-tune FPS","title":"List of possible options","text":"","category":"section"},{"location":"fine-tuneFPS/","page":"Fine-tune FPS","title":"Fine-tune FPS","text":"Find below a list of the main options of fps_solve.","category":"page"},{"location":"fine-tuneFPS/#Tolerances-on-the-problem","page":"Fine-tune FPS","title":"Tolerances on the problem","text":"","category":"section"},{"location":"fine-tuneFPS/","page":"Fine-tune FPS","title":"Fine-tune FPS","text":"We use Stopping.jl to control the algorithmic flow, we refer to Stopping.jl and https://solverstoppingjulia.github.io for tutorials and documentation. By default, we use the function Fletcher_penalty_optimality_check as optimality check, and the default tol_check is rtol [1 + c(x₀); 1 + ∇f(x₀)] with rtol = 1e-7.","category":"page"},{"location":"fine-tuneFPS/","page":"Fine-tune FPS","title":"Fine-tune FPS","text":"Additional parameters used in stopping the algorithm are defined in the following table.","category":"page"},{"location":"fine-tuneFPS/","page":"Fine-tune FPS","title":"Fine-tune FPS","text":"Parameters Type Default Description\nlagrange_bound Real 1 / sqrt(eps(T)) bounds on estimated Lagrange multipliers.","category":"page"},{"location":"fine-tuneFPS/#Algorithmic-parameters","page":"Fine-tune FPS","title":"Algorithmic parameters","text":"","category":"section"},{"location":"fine-tuneFPS/","page":"Fine-tune FPS","title":"Fine-tune FPS","text":"The metadata is defined in a AlgoData structure at the initialization of FPSSolver.","category":"page"},{"location":"fine-tuneFPS/","page":"Fine-tune FPS","title":"Fine-tune FPS","text":"Parameters Type Default Description\nσ_0 Real 1e3 Initialize subproblem's parameter σ\nσ_max Real 1 / √eps(T) Maximum value for subproblem's parameter σ\nσ_update Real T(2) Update subproblem's parameter σ\nρ_0 Real T(2) Initialize subproblem's parameter ρ\nρ_max Real 1 / √eps(T) Maximum value for subproblem's parameter ρ\nρ_update Real T(2) Update subproblem's parameter ρ\nδ_0 Real √eps(T) Initialize subproblem's parameter δ\nδ_max Real 1 / √eps(T) Maximum value for subproblem's parameter δ\nδ_update Real T(10) Update subproblem's parameter δ\nη_1 Real zero(T) Initialize subproblem's parameter η\nη_update Real one(T) Update subproblem's parameter η\nyM Real typemax(T) bound on the Lagrange multipliers\nΔ Real T(0.95) expected decrease in feasibility between two iterations\nunconstrained_solver Function StoppingInterface.isknitroinstalled ? NLPModelsKnitro.knitro : ipopt solver used for the subproblem, see also JSOSolvers.jl\nsubpbunboundedthreshold Real 1 / √eps(T) below the opposite of this value, the subproblem is unbounded\natol_sub Function atol -> atol absolute tolerance for the subproblem in function of atol\nrtol_sub Function rtol -> rtol relative tolerance for the subproblem in function of rtol\nhessian_approx either Val(1) or Val(2) Val(2) it selects the hessian approximation\nconvex_subproblem Bool false true if the subproblem is convex. Useful to set the convex option in knitro.\nqds_solver Symbol :ldlt Initialize the QDSolver to solve quasi-definite systems, either :ldlt or :iterative.","category":"page"},{"location":"fine-tuneFPS/#Feasibility-step","page":"Fine-tune FPS","title":"Feasibility step","text":"","category":"section"},{"location":"fine-tuneFPS/","page":"Fine-tune FPS","title":"Fine-tune FPS","text":"The metadata for the feasibility procedure is defined in a GNSolver structure at the initialization of FPSSolver.","category":"page"},{"location":"fine-tuneFPS/","page":"Fine-tune FPS","title":"Fine-tune FPS","text":"Parameters Type Default Description\nη₁ Real 1e-3 Feasibility step: decrease the trust-region radius when Ared/Pred < η₁.\nη₂ Real 0.66 Feasibility step: increase the trust-region radius when Ared/Pred > η₂.\nσ₁ Real 0.25 Feasibility step: decrease coefficient of the trust-region radius.\nσ₂ Real 2.0 Feasibility step: increase coefficient of the trust-region radius.\nΔ₀ Real 1.0 Feasibility step: initial radius.\nfeasexpecteddecrease Real 0.95 Feasibility step: bad steps are when ‖c(z)‖ / ‖c(x)‖ >feasexpecteddecrease.\nbadstepslim Integer 3 Feasibility step: consecutive bad steps before using a second order step.\nTRcomputestep KrylovSolver LsmrSolver Compute the direction in feasibility step.\naggressive_step KrylovSolver CgSolver Compute the (aggressive) direction in feasibility step.","category":"page"},{"location":"reference/#Reference","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"​","category":"page"},{"location":"reference/#Contents","page":"Reference","title":"Contents","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"​","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"Pages = [\"reference.md\"]","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"​","category":"page"},{"location":"reference/#Index","page":"Reference","title":"Index","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"​","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"Pages = [\"reference.md\"]","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"​","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [FletcherPenaltyNLPSolver]","category":"page"},{"location":"reference/#FletcherPenaltyNLPSolver.AlgoData","page":"Reference","title":"FletcherPenaltyNLPSolver.AlgoData","text":"AlgoData(; kwargs...) \nAlgoData(T::DataType; kwargs...)\n\nStructure containing all the parameters used in the fps_solve call. T is the datatype used in the algorithm, by default it is Float64. Returns a AlgoData structure.\n\nArguments\n\nThe keyword arguments may include:\n\nσ_0::Real = T(1e3): Initialize subproblem's parameter σ;\nσ_max::Real = 1 / √eps(T): Maximum value for subproblem's parameter σ;\nσ_update::Real = T(2): Update subproblem's parameter σ;\nρ_0::Real = one(T): Initialize subproblem's parameter ρ;\nρ_max::Real = 1 / √eps(T): Maximum value for subproblem's parameter ρ;\nρ_update::Real = T(2): Update subproblem's parameter ρ;\nδ_0::Real = √eps(T): Initialize subproblem's parameter δ;\nδ_max::Real = 1 / √eps(T): Maximum value for subproblem's parameter δ;\nδ_update::Real = T(10): Update subproblem's parameter δ;\nη_1::Real = zero(T): Initialize subproblem's parameter η;\nη_update::Real = one(T): Update subproblem's parameter η;\nyM::Real = typemax(T): bound on the Lagrange multipliers;\nΔ::Real = T(0.95): expected decrease in feasibility between two iterations;\nunconstrained_solver::Function = StoppingInterface.is_knitro_installed ? NLPModelsKnitro.knitro : ipopt: solver used for the subproblem;\nsubpb_unbounded_threshold::Real = 1 / √eps(T): below the opposite of this value, the subproblem is unbounded;\natol_sub::Function = atol -> atol: absolute tolerance for the subproblem in function of atol;\nrtol_sub::Function = rtol -> rtol: relative tolerance for the subproblem in function of rtol;\nhessian_approx = Val(2): either Val(1) or Val(2), it selects the hessian approximation;\nconvex_subproblem::Bool = false: true if the subproblem is convex. Useful to set the convex option in knitro.\n\nFor more details, we refer to the package documentation fine-tuneFPS.md. \n\n\n\n\n\n","category":"type"},{"location":"reference/#FletcherPenaltyNLPSolver.DirectSolver","page":"Reference","title":"FletcherPenaltyNLPSolver.DirectSolver","text":"DirectSolver(nlp::AbstractNLPModel, ::T) <: QDSolver\n\n\n\n\n\n","category":"type"},{"location":"reference/#FletcherPenaltyNLPSolver.FPSSSolver","page":"Reference","title":"FletcherPenaltyNLPSolver.FPSSSolver","text":"FPSSSolver(nlp, ::T; kwargs...)\n\nStructure regrouping all the structure used during the fps_solve call. It returns a FPSSSolver structure.\n\nArguments\n\nThe keyword arguments may include:\n\nmeta::AlgoData{T}: see AlgoData;\nworkspace: allocated space for the solver itself;\nqdsolver: solver structure for the linear algebra part, contains allocation for this part. By default a LDLtSolver, but an alternative is IterativeSolver ;\nunconstrained_solver::UnconstrainedSolver: by default a KnitroSolver, options: IpoptSolver, TronSolver, LBFGSSolver;\nfeasibility_solver: by default a GNSolver, see GNSolver;\n\nNote:\n\nunconstrained_solver is not used.\nthe qdsolver is accessible from the dictionary qdsolver_correspondence.\n\n\n\n\n\n","category":"type"},{"location":"reference/#FletcherPenaltyNLPSolver.FletcherPenaltyNLP","page":"Reference","title":"FletcherPenaltyNLPSolver.FletcherPenaltyNLP","text":"FletcherPenaltyNLP(nlp, σ, hessian_approx; kwargs...)\nFletcherPenaltyNLP(nlp, σ, hessian_approx, x; qds = LDLtSolver(nlp, S(0)))\nFletcherPenaltyNLP(nlp, σ, ρ, δ, hessian_approx; kwargs...)\nFletcherPenaltyNLP(nlp, σ, ρ, δ, hessian_approx, x; qds = LDLtSolver(nlp, S(0)))\nFletcherPenaltyNLP(nlp; σ_0::Real = one(eltype(nlp.meta.x0)), ρ_0::Real = zero(eltype(nlp.meta.x0)), δ_0::Real = zero(eltype(nlp.meta.x0)), hessian_approx = Val(2), x0 = nlp.meta.x0, kwargs...)\n\nWe consider here the implementation of Fletcher's exact penalty method for the minimization problem:\n\n    minₓ    f(x)    st    c(x) = ℓ l  x  u\n\nusing Fletcher penalty function:\n\n    minₓ    f(x) - (c(x) - ℓ)^T ys(x) + 05 ρ c(x) - ℓ²₂    st    l  x  u\n\nwhere\n\n    ys(x)        arg min_y    05 A(x)y - g(x)²₂ + σ (c(x) - ℓ)^T y + 05  δ ²₂\n\nArguments\n\nnlp::AbstractNLPModel: the model solved, see NLPModels.jl;\nx::AbstractVector: Initial guess. If x is not specified, then nlp.meta.x0 is used;\nσ, ρ, δ parameters of the subproblem;\nhessian_approx either Val(1) or Val(2) for the hessian approximation.\nqds: solver structure for the linear algebra computations, see LDLtSolver or IterativeSolver.\n\nNotes:\n\nEvaluation of the obj, grad, objgrad functions evaluate functions from the orginial nlp. These values are stored in fx, cx, gx.\nThe value of the penalty vector ys is also stored.\nThe hessian's structure is dense.\n\nExamples\n\njulia> using FletcherPenaltyNLPSolver, ADNLPModels\njulia> nlp = ADNLPModel(x -> 100 * (x[2] - x[1]^2)^2 + (x[1] - 1)^2, [-1.2; 1.0])\njulia> fp_sos  = FletcherPenaltyNLP(nlp)\n\n\n\n\n\n","category":"type"},{"location":"reference/#FletcherPenaltyNLPSolver.GNSolver","page":"Reference","title":"FletcherPenaltyNLPSolver.GNSolver","text":"GNSolver(x, y; kwargs...)\n\nStructure containing all the parameters used in the feasibility step. x is an intial guess, and y is an initial guess for the Lagrange multiplier. Returns a GNSolver structure.\n\nArguments\n\nThe keyword arguments may include:\n\nη₁::T=T(1e-3): Feasibility step: decrease the trust-region radius when Ared/Pred < η₁.\nη₂::T=T(0.66): Feasibility step: increase the trust-region radius when Ared/Pred > η₂.\nσ₁::T=T(0.25): Feasibility step: decrease coefficient of the trust-region radius.\nσ₂::T=T(2.0): Feasibility step: increase coefficient of the trust-region radius.\nΔ₀::T=one(T): Feasibility step: initial radius.\nbad_steps_lim::Integer=3: Feasibility step: consecutive bad steps before using a second order step.\nfeas_expected_decrease::T=T(0.95): Feasibility step: bad steps are when ‖c(z)‖ / ‖c(x)‖ >feas_expected_decrease.\nTR_compute_step = LsmrSolver(length(y0), length(x0), S): Compute the direction in feasibility step.\naggressive_step = CgSolver(length(x0), length(x0), S): Compute the direction in feasibility step in agressive mode.\n\n\n\n\n\n","category":"type"},{"location":"reference/#FletcherPenaltyNLPSolver.IpoptSolver","page":"Reference","title":"FletcherPenaltyNLPSolver.IpoptSolver","text":"IpoptSolver <: UnconstrainedSolver\n\nStructure used for the subproblem solve with ipopt.\n\n\n\n\n\n","category":"type"},{"location":"reference/#FletcherPenaltyNLPSolver.IterativeSolver","page":"Reference","title":"FletcherPenaltyNLPSolver.IterativeSolver","text":"IterativeSolver(nlp::AbstractNLPModel, ::T) <: QDSolver\n\nIt uses Krylov.jl methods to solve least-squares and least-norm problems.\n\n\n\n\n\n","category":"type"},{"location":"reference/#FletcherPenaltyNLPSolver.KnitroSolver","page":"Reference","title":"FletcherPenaltyNLPSolver.KnitroSolver","text":"KnitroSolver <: UnconstrainedSolver\n\nStructure used for the subproblem solve with knitro.\n\n\n\n\n\n","category":"type"},{"location":"reference/#FletcherPenaltyNLPSolver.LBFGSSolver","page":"Reference","title":"FletcherPenaltyNLPSolver.LBFGSSolver","text":"LBFGSolver <: UnconstrainedSolver\n\nStructure used for the subproblem solve with lbfgs.\n\n\n\n\n\n","category":"type"},{"location":"reference/#FletcherPenaltyNLPSolver.LDLtSolver","page":"Reference","title":"FletcherPenaltyNLPSolver.LDLtSolver","text":"LDLtSolver(nlp::AbstractNLPModel, ::T) <: QDSolver\n\nIt uses LDLFactorization.jl methods to solve least-squares and least-norm problems.\n\n\n\n\n\n","category":"type"},{"location":"reference/#FletcherPenaltyNLPSolver.LUSolver","page":"Reference","title":"FletcherPenaltyNLPSolver.LUSolver","text":"LUSolver(nlp::AbstractNLPModel, ::T) <: QDSolver\n\n\n\n\n\n","category":"type"},{"location":"reference/#FletcherPenaltyNLPSolver.QDSolver","page":"Reference","title":"FletcherPenaltyNLPSolver.QDSolver","text":"QDSolver\n\nAbstract structure handling parameters for the system\n\n   In   A          \n   A  -nlpδ*Im \n\nthat we are solving twice.\n\nIts implementation should define:\n\nsolve_two_extras\nsolve_two_least_squares\nsolve_two_mixed\n\n\n\n\n\n","category":"type"},{"location":"reference/#FletcherPenaltyNLPSolver.TronSolver","page":"Reference","title":"FletcherPenaltyNLPSolver.TronSolver","text":"TronSolver <: UnconstrainedSolver\n\nStructure used for the subproblem solve with tron.\n\n\n\n\n\n","category":"type"},{"location":"reference/#FletcherPenaltyNLPSolver.UnconstrainedSolver","page":"Reference","title":"FletcherPenaltyNLPSolver.UnconstrainedSolver","text":"UnconstrainedSolver\n\nAbstract structure used for the subproblem solve.\n\n\n\n\n\n","category":"type"},{"location":"reference/#FletcherPenaltyNLPSolver.Fletcher_penalty_optimality_check-Union{Tuple{S}, Tuple{T}, Tuple{NLPModels.AbstractNLPModel{T, S}, Stopping.NLPAtX}} where {T, S}","page":"Reference","title":"FletcherPenaltyNLPSolver.Fletcher_penalty_optimality_check","text":"Fletcher_penalty_optimality_check(pb::AbstractNLPModel, state::NLPAtX)\n\nOptimality function used by default in the algorithm. An alternative is to use the function KKT from Stopping.jl.\n\nThe function returns a vector of length ncon + nvar containing:\n\n|c(x) - lcon| / |x|₂\nres / |λ|₂ ; x - max(min(x - res, uvar), lvar)) if it has bounds\n\nThe fields x, cx and res need to be filled. If state.lambda is nothing then we take |λ|₂=1.\n\n\n\n\n\n","category":"method"},{"location":"reference/#FletcherPenaltyNLPSolver.TR_lsmr-Union{Tuple{T}, Tuple{Any, AbstractVector{T}, Union{AbstractMatrix{T}, LinearOperators.LinearOperator{T}}, AbstractFloat, T, AbstractFloat, AbstractVector{T}}} where T","page":"Reference","title":"FletcherPenaltyNLPSolver.TR_lsmr","text":"TR_lsmr(solver, cz, Jz, ctol, Δ, normcz, Jd)\n\nCompute a direction d such that\n\nbeginaligned\nmin_d quad  c + Jz d  \ntextst quad  d leq Delta\nendaligned\n\nusing lsmr method from Krylov.jl.\n\nOutput\n\nd: solution\nJd: product of the solution with J.\ninfeasible: true if the problem is infeasible.\nsolved: true if the problem has been successfully solved.\n\n\n\n\n\n","category":"method"},{"location":"reference/#FletcherPenaltyNLPSolver._compute_ys_gs!-Union{Tuple{T}, Tuple{FletcherPenaltyNLP, AbstractVector{T}}} where T","page":"Reference","title":"FletcherPenaltyNLPSolver._compute_ys_gs!","text":"gs, ys, v, w = _compute_ys_gs!(nlp, x)\n\nCompute the Lagrange multipliers and the gradient of the Lagrangian function in-place.\n\n\n\n\n\n","category":"method"},{"location":"reference/#FletcherPenaltyNLPSolver.feasibility_step-Union{Tuple{S}, Tuple{T}, Tuple{FletcherPenaltyNLPSolver.GNSolver, NLPModels.AbstractNLPModel, AbstractVector{T}, AbstractVector{T}, T, Union{AbstractMatrix{T}, LinearOperators.LinearOperator{T}}, T, AbstractFloat}} where {T, S}","page":"Reference","title":"FletcherPenaltyNLPSolver.feasibility_step","text":"feasibility_step(feasibility_solver, nlp, x, cx, normcx, Jx, ρ, ctol; kwargs...)\n\nApproximately solves min ‖c(x) - l‖, where l is nlp.meta.lcon, using a trust-region Levenberg-Marquardt method.\n\nArguments\n\nη₁::AbstractFloat = feasibility_solver.feas_η₁: decrease the trust-region radius when Ared/Pred < η₁.\nη₂::AbstractFloat = feasibility_solver.feas_η₂: increase the trust-region radius when Ared/Pred > η₂.\nσ₁::AbstractFloat = feasibility_solver.feas_σ₁: decrease coefficient of the trust-region radius.\nσ₂::AbstractFloat = feasibility_solver.feas_σ₂:increase coefficient of the trust-region radius.\nΔ₀::T = feasibility_solver.feas_Δ₀: initial trust-region radius.\nbad_steps_lim::Integer = feasibility_solver.bad_steps_lim: consecutive bad steps before using a second order step.\nexpected_decrease::T = feasibility_solver.feas_expected_decrease: bad steps are when ‖c(z)‖ / ‖c(x)‖ >feas_expected_decrease.\nmax_eval::Int = 1_000: maximum evaluations.\nmax_time::AbstractFloat = 60.0: maximum time.\nmax_feas_iter::Int = typemax(Int64): maximum number of iterations.\n\nOutput\n\nz, cz, normcz, Jz: the new iterate, and updated evaluations.\nstatus: Computation status. Possible outcomes are: :success, max_eval, max_time, max_iter, unknown_tired, :infeasible, :unknown.\n\n\n\n\n\n","category":"method"},{"location":"reference/#FletcherPenaltyNLPSolver.fps_solve-Union{Tuple{NLPModels.AbstractNLPModel}, Tuple{T}, Tuple{NLPModels.AbstractNLPModel, AbstractVector{T}}} where T","page":"Reference","title":"FletcherPenaltyNLPSolver.fps_solve","text":"fps_solve(nlp::AbstractNLPModel, x0::AbstractVector{T} = nlp.meta.x0; subsolver_verbose::Int = 0, lagrange_bound = 1 / sqrt(eps(T)), kwargs...)\n\nCompute a local minimum of a bound and equality-constrained optimization problem using Fletcher's penalty function and the implementation described in\n\nEstrin, R., Friedlander, M. P., Orban, D., & Saunders, M. A. (2020).\nImplementing a smooth exact penalty function for equality-constrained nonlinear optimization.\nSIAM Journal on Scientific Computing, 42(3), A1809-A1835.\nhttps://doi.org/10.1137/19M1238265\n\nFor advanced usage, the principal call to the solver uses a NLPStopping, see Stopping.jl.\n\nfps_solve(stp::NLPStopping, fpssolver::FPSSSolver{T, QDS, US}; subsolver_verbose::Int = 0, lagrange_bound::T = 1 / sqrt(eps(T)))\nfps_solve(stp::NLPStopping; subsolver_verbose::Int = 0, lagrange_bound = 1 / sqrt(eps()), kwargs...)\n\nArguments\n\nnlp::AbstractNLPModel: the model solved, see NLPModels.jl;\nx: Initial guess. If x is not specified, then nlp.meta.x0 is used.\n\nKeyword arguments\n\nfpssolver: see FPSSSolver;\nsubsolver_verbose::Int = 0: if > 0, display iteration information of the subsolver;\nlagrange_bound = 1 / sqrt(eps()): bound used to declare the Lagrange multiplier unbounded.\n\nAll the information regarding stopping criteria can be set in the NLPStopping object. Additional kwargs are given to the NLPStopping. By default, the optimality condition used to declare optimality is Fletcher_penalty_optimality_check.\n\nOutput\n\nThe returned value is a GenericExecutionStats, see SolverCore.jl.\n\nIf one define a Stopping before calling fps_solve, it is possible to access all the information computed by the algorithm.\n\nNotes\n\nIf the problem has inequalities, we use slack variables to get only equalities and bounds via NLPModelsModifiers.jl.\nstp.current_state.res contains the gradient of Fletcher's penalty function.\nunconstrained_solver must take an NLPStopping as input, see StoppingInterface.jl.\n\nExamples\n\njulia> using FletcherPenaltyNLPSolver, ADNLPModels\njulia> nlp = ADNLPModel(x -> 100 * (x[2] - x[1]^2)^2 + (x[1] - 1)^2, [-1.2; 1.0]);\njulia> stats = fps_solve(nlp)\n\"Execution stats: first-order stationary\"\n\n\n\n\n\n","category":"method"},{"location":"reference/#FletcherPenaltyNLPSolver.go_log-Tuple{Any, Any, Any, Any, String}","page":"Reference","title":"FletcherPenaltyNLPSolver.go_log","text":"go_log(stp, sub_stp, fx, ncx, mess::String)\n\nLogging shortcut.\n\n\n\n\n\n","category":"method"},{"location":"reference/#FletcherPenaltyNLPSolver.linear_system2-Union{Tuple{T}, Tuple{FletcherPenaltyNLP, AbstractVector{T}}} where T","page":"Reference","title":"FletcherPenaltyNLPSolver.linear_system2","text":"p1, q1, p2, q2 = linear_system2(nlp, x)\n\nCall to solve_two_mixed(nlp, x, nlp.gx, nlp.cx), see solve_two_mixed.\n\n\n\n\n\n","category":"method"},{"location":"reference/#FletcherPenaltyNLPSolver.random_restoration!-Tuple{Any, Any, Any}","page":"Reference","title":"FletcherPenaltyNLPSolver.random_restoration!","text":"random_restoration!(meta, stp, sub_stp)\n\nAdd a random perturbation to the current iterate.\n\n\n\n\n\n","category":"method"},{"location":"reference/#FletcherPenaltyNLPSolver.restoration_feasibility!-NTuple{6, Any}","page":"Reference","title":"FletcherPenaltyNLPSolver.restoration_feasibility!","text":"restoration_feasibility!(feasibility_solver, meta, stp, sub_stp, feas_tol, ncx)\n\nTry to find a feasible point, see feasibility_step.\n\n\n\n\n\n","category":"method"},{"location":"reference/#FletcherPenaltyNLPSolver.solve_two_extras","page":"Reference","title":"FletcherPenaltyNLPSolver.solve_two_extras","text":"invJtJJv, invJtJSsv = solve_two_extras(nlp, x, rhs1, rhs2)\n\nThe IterativeSolver variant solve successively a regularized least square, see solve_least_square, and a regularized minres. It returns only a warning if the method failed.\n\nThe LDLtSolver variant use successively a regularized cgls and a regularized minres.\n\n\n\n\n\n","category":"function"},{"location":"reference/#FletcherPenaltyNLPSolver.solve_two_least_squares","page":"Reference","title":"FletcherPenaltyNLPSolver.solve_two_least_squares","text":"p1, q1, p2, q2 = solve_two_least_squares(nlp, x, rhs1, rhs2)\n\nSolve successively two least square regularized by √nlp.δ:\n\n    min  c q - rhs  + δ  q ^2\n\nrhs1 and rhs2 are both of size nlp.meta.nvar.\n\nThe IterativeSolver variant uses two calls to a Krylov.jl method, see solve_least_square. Note that nlp.Aop is not re-evaluated in this case. It returns only a warning if the method failed.\n\nThe LDLtSolver variant use an LDLt factorization to solve the large system.\n\n\n\n\n\n","category":"function"},{"location":"reference/#FletcherPenaltyNLPSolver.solve_two_mixed","page":"Reference","title":"FletcherPenaltyNLPSolver.solve_two_mixed","text":"p1, q1, p2, q2 = solve_two_mixed(nlp, x, rhs1, rhs2)\n\nSolve successively a least square regularized by √nlp.δ:\n\n    min  c q - rhs  + δ  q ^2\n\nand a least-norm problem.\n\nrhs1 is of size nlp.meta.nvar, and rhs2 is of size nlp.meta.ncon.\n\nThe IterativeSolver variant uses two calls to a Krylov.jl method, see solve_least_square and solve_least_norm. It returns only a warning if the method failed.\n\nThe LDLtSolver variant use an LDLt factorization to solve the large system.\n\n\n\n\n\n","category":"function"},{"location":"reference/#FletcherPenaltyNLPSolver.update_parameters!-Tuple{Any, Any, Any}","page":"Reference","title":"FletcherPenaltyNLPSolver.update_parameters!","text":"update_parameters!(meta, sub_stp, feas)\n\nUpdate σ. If the current iterate also update ρ.\n\n\n\n\n\n","category":"method"},{"location":"reference/#FletcherPenaltyNLPSolver.update_parameters_unbdd!-Tuple{Any, Any, Any}","page":"Reference","title":"FletcherPenaltyNLPSolver.update_parameters_unbdd!","text":"update_parameters_unbdd!(meta, sub_stp, feas)\n\nStart or update δ, then call update_parameters!(meta, sub_stp, feas)\n\n\n\n\n\n","category":"method"},{"location":"#FletcherPenaltyNLPSolver-Fletcher's-Penalty-Method","page":"Introduction","title":"FletcherPenaltyNLPSolver - Fletcher's Penalty Method","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"FPS is a solver for equality-constrained nonlinear problems, i.e., optimization problems of the form","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"  min_x f(x) quad textst quad c(x) = 0 quad  ℓ  x  u","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"It uses other JuliaSmoothOptimizers packages for development. In particular, NLPModels.jl is used for defining the problem, and SolverCore.jl for the output. If a general inequality-constrained problem is given to the solver, it solves the problem reformulated as a SlackModel from NLPModelsModifiers.jl.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"We refer to juliasmoothoptimizers.github.io for tutorials on the NLPModel API. This framework allows the usage of models from Ampl (using AmplNLReader.jl), CUTEst (using CUTEst.jl), JuMP (using NLPModelsJuMP.jl), PDE-constrained optimization problems (using PDENLPModels.jl) and models defined with automatic differentiation (using ADNLPModels.jl).","category":"page"},{"location":"#Algorithm","page":"Introduction","title":"Algorithm","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"The function fps_solver solves a nonlinear optimization problem by iteratively solving  the bound-constrained optimization problem using Fletcher penalty function:","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"  beginaligned\n    min_x   f(x) - c(x)^T lambda_delta(x) + fracrho2c(x)^2_2 \n    mboxwhere  lambda_delta(x) in textargmin_y frac12 nabla c(x)^T y - nabla f(x) ^2_2 + sigma c(x)^T y + fracdelta2y^2\n  endaligned","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"For equality-constrained problems, the method iteratively solves an unconstrained problem. For bound and equality-constrained problems, the subproblems are bound-constrained problems. Any solver compatible with Stopping.jl can be used. By default, we use ipopt from NLPModelsIpopt.jl to solve the subproblem, but other solvers can be used such as knitro from NLPModelsKnitro.jl or any solvers from JSOSolvers.jl. The Stopping version of these solvers is available in StoppingInterface.jl.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"It uses LDLFactorizations.jl by default to evaluate the derivatives of the penalized subproblem, but one can also use a matrix-free version with Krylov.jl.","category":"page"},{"location":"#References","page":"Introduction","title":"References","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"Estrin, R., Friedlander, M. P., Orban, D., & Saunders, M. A. (2020). Implementing a smooth exact penalty function for equality-constrained nonlinear optimization. SIAM Journal on Scientific Computing, 42(3), A1809-A1835. 10.1137/19M1238265","category":"page"},{"location":"#How-to-Cite","page":"Introduction","title":"How to Cite","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"If you use FletcherPenaltyNLPSolver in your work, please cite using the format given in CITATION.cff.","category":"page"},{"location":"#Installation","page":"Introduction","title":"Installation","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"pkg> add https://github.com/tmigot/FletcherPenaltyNLPSolver","category":"page"},{"location":"#Example","page":"Introduction","title":"Example","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"We consider in this example the minization of the Rosenbrock function.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"    min_x  100 (x₂ - x₁²)² + (x₁ - 1)²","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The problem is modeled using ADNLPModels.jl with [-1.2; 1.0] as default initial point, and then solved using fps_solve.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using FletcherPenaltyNLPSolver, ADNLPModels\n\n# Rosenbrock\nnlp = ADNLPModel(x -> 100 * (x[2] - x[1]^2)^2 + (x[1] - 1)^2, [-1.2; 1.0])\nstats = fps_solve(nlp)","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"We consider in this example the minization of the Rosenbrock function over an inequality constraint.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"    min_x  100 (x₂ - x₁²)² + (x₁ - 1)² quad textst quad  0  x₁x₂  1","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"The problem is modeled using ADNLPModels.jl with [-1.2; 1.0] as default initial point, and then solved using fps_solve.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"using FletcherPenaltyNLPSolver, ADNLPModels\n\nnlp = ADNLPModel(\n  x -> 100 * (x[2] - x[1]^2)^2 + (x[1] - 1)^2,\n  [-1.2; 1.0],\n  x->[x[1] * x[2]],\n  [0.0],\n  [1.0],\n)\nstats = fps_solve(nlp)","category":"page"},{"location":"#Bug-reports-and-discussions","page":"Introduction","title":"Bug reports and discussions","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"If you think you found a bug, feel free to open an issue. Focused suggestions and requests can also be opened as issues. Before opening a pull request, start an issue or a discussion on the topic, please.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"If you want to ask a question not suited for a bug report, feel free to start a discussion here. This forum is for general discussion about this repository and the JuliaSmoothOptimizers, so questions about any of our packages are welcome.","category":"page"},{"location":"tutorial/#Tutorial","page":"Tutorial","title":"Tutorial","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Pages = [\"tutorial.md\"]","category":"page"},{"location":"tutorial/#FletcherPenaltyNLPSolver-Tutorial","page":"Tutorial","title":"FletcherPenaltyNLPSolver Tutorial","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"In this tutorial, we explore on small instances various possibilities offered by fps_solve defined in the package FletcherPenaltyNLPSolver.","category":"page"},{"location":"tutorial/#Type-stable-algorithm","page":"Tutorial","title":"Type stable algorithm","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The algorithm is implemented in pure Julia, so if one also chooses an unconstrained solver in pure Julia, we can Julia's type stability to solve optimization problems in a precision different than Float64. In the following example, we use tron from JSOSolvers.jl on a simple example in Float32.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"using ADNLPModels, FletcherPenaltyNLPSolver, JSOSolvers\nT = Float32\nnlp = ADNLPModel(x -> (1 - x[1])^2, T[-1.2; 1.0], x -> [10 * (x[2] - x[1]^2)], T[0.0], T[0.0])\nstats = fps_solve(nlp, hessian_approx = Val(2), unconstrained_solver = tron, rtol = T(1e-6))\n(stats.dual_feas, stats.primal_feas, stats.status, typeof(stats.solution))","category":"page"},{"location":"tutorial/#A-factorization-free-solver","page":"Tutorial","title":"A factorization-free solver","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"The main advantage of fps_solver is the possibility to use Hessian and Jacobian-vector products only, whenever one uses a subproblem solver with the same property. So, it is not necessary to compute and store explicitly those matrices. In the following example, we choose a problem with equality constraints from OptimizationProblems.jl.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"using ADNLPModels, FletcherPenaltyNLPSolver, OptimizationProblems\nnlp = OptimizationProblems.ADNLPProblems.hs28()\nstats = fps_solve(nlp, unconstrained_solver = tron, qds_solver = :iterative)\n(stats.dual_feas, stats.primal_feas, stats.status, stats.elapsed_time)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Exploring nlp's counter, we can see that no Hessian or Jacobian matrix has been evaluated.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"nlp.counters","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"We can compare this result with ipopt that uses the Jacobian and Hessian matrices.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"using NLPModels\nreset!(nlp);\nstats = fps_solve(nlp, unconstrained_solver = ipopt, qds_solver = :iterative)\n(stats.dual_feas, stats.primal_feas, stats.status, stats.elapsed_time)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"nlp.counters","category":"page"},{"location":"tutorial/#Stopping-solver","page":"Tutorial","title":"Stopping-solver","text":"","category":"section"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"using ADNLPModels, FletcherPenaltyNLPSolver, Stopping\nf(x) = (x[1] - 1)^2 + 4 * (x[2] - x[1]^2)^2\nc(x) = [x[1]^2 + x[2]^2 - 2]\nT = Float64\nx0 = T[-1.2; 1.0]\nℓ, u = zeros(T, 2), 2 * ones(T, 2)\nnlp = ADNLPModel(f, x0, ℓ, u, c, zeros(1), zeros(1))\n\nstp = NLPStopping(nlp)\nstats = fps_solve(stp)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"It is then possible to explore the various quantities computed by the algorithm. For instance, recompute the gradient of the Lagrangian.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"state = stp.current_state\nstate.gx + state.Jx' * state.lambda","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"Another possibility is to reuse the Stopping for another solve.","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"new_x0 = 4 * ones(2)\nreinit!(stp, rstate = true, x = new_x0)\nreset!(stp.pb)\nstats = fps_solve(stp)","category":"page"},{"location":"tutorial/","page":"Tutorial","title":"Tutorial","text":"We refer to Stopping.jl and https://solverstoppingjulia.github.io for tutorials and documentation.","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"EditURL = \"https://github.com/tmigot/FletcherPenaltyNLPSolver/blob/main/docs/assets/example.jl\"","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"(Image: Binder)","category":"page"},{"location":"example/#Solve-Large-Scale-Problem-with-FletcherPenaltyNLPSolver","page":"Large-scale example","title":"Solve Large-Scale Problem with FletcherPenaltyNLPSolver","text":"","category":"section"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"In this tutorial we use fps_solve to solve a large-scale optimization problem resulting from the discretization of a PDE-constrained optimization problem and compare the solve with Ipopt.","category":"page"},{"location":"example/#Problem-Statement","page":"Large-scale example","title":"Problem Statement","text":"","category":"section"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"Let Ω = (-1,1)², we solve the following distributed Poisson control problem with Dirichlet boundary:","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"   leftlbrace\n   beginaligned\n      min_y in H^1_0 u in H^1 quad   frac12 int_Omega y(x) - y_d(x)^2dx + fracalpha2 int_Omega u^2dx \n      textst  -Delta y = h + u quad x in Omega \n                   y = 0 quad x in partial Omega\n   endaligned\n   right","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"where yd(x) = -x₁² and α = 1e-2. The force term is h(x₁, x₂) = - sin(ω x₁)sin(ω x₂) with  ω = π - 1/8.","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"We refer to Gridap.jl for more details on modeling PDEs and PDENLPModels.jl for PDE-constrained optimization problems.","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"using Gridap, PDENLPModels","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"Definition of the domain and discretization","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"n = 20\ndomain = (-1, 1, -1, 1)\npartition = (n, n)\nmodel = CartesianDiscreteModel(domain, partition)","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"CartesianDiscreteModel()","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"Definition of the FE-spaces","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"reffe = ReferenceFE(lagrangian, Float64, 2)\nXpde = TestFESpace(model, reffe; conformity = :H1, dirichlet_tags = \"boundary\")\ny0(x) = 0.0\nYpde = TrialFESpace(Xpde, y0)\n\nreffe_con = ReferenceFE(lagrangian, Float64, 1)\nXcon = TestFESpace(model, reffe_con; conformity = :H1)\nYcon = TrialFESpace(Xcon)\nY = MultiFieldFESpace([Ypde, Ycon])","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"MultiFieldFESpace()","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"Integration machinery","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"trian = Triangulation(model)\ndegree = 1\ndΩ = Measure(trian, degree)","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"Measure()","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"Objective function","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"yd(x) = -x[1]^2\nα = 1e-2\nfunction f(y, u)\n  ∫(0.5 * (yd - y) * (yd - y) + 0.5 * α * u * u) * dΩ\nend","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"f (generic function with 1 method)","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"Definition of the constraint operator","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"ω = π - 1 / 8\nh(x) = -sin(ω * x[1]) * sin(ω * x[2])\nfunction res(y, u, v)\n  ∫(∇(v) ⊙ ∇(y) - v * u - v * h) * dΩ\nend\nop = FEOperator(res, Y, Xpde)","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"FEOperatorFromWeakForm()","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"Definition of the initial guess","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"npde = Gridap.FESpaces.num_free_dofs(Ypde)\nncon = Gridap.FESpaces.num_free_dofs(Ycon)\nx0 = zeros(npde + ncon);","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"Overall, we built a GridapPDENLPModel, which implements the NLPModels.jl API.","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"nlp = GridapPDENLPModel(x0, f, trian, Ypde, Ycon, Xpde, Xcon, op, name = \"Control elastic membrane\")\n\n(nlp.meta.nvar, nlp.meta.ncon)","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"(1962, 1521)","category":"page"},{"location":"example/#Find-a-Feasible-Point","page":"Large-scale example","title":"Find a Feasible Point","text":"","category":"section"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"Before solving the previously defined model, we will first improve our initial guess. We use FeasibilityResidual from NLPModelsModifiers.jl to convert the NLPModel as an NLSModel. Then, using trunk, a solver for least-squares problems implemented in JSOSolvers.jl, we find An improved guess which is close to being feasible for our large-scale problem. By default, a JSO-compliant solver such as trunk (the same applies to fps_solve) uses by default nlp.meta.x0 as an initial guess.","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"using JSOSolvers, NLPModelsModifiers\n\nnls = FeasibilityResidual(nlp)\nstats_trunk = trunk(nls)","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"\"Execution stats: first-order stationary\"","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"We check the solution from the stats returned by trunk:","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"norm(cons(nlp, stats_trunk.solution))","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"1.6058259477971256e-5","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"We will use the solution found to initialize our solvers.","category":"page"},{"location":"example/#Solve-the-Problem","page":"Large-scale example","title":"Solve the Problem","text":"","category":"section"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"Finally, we are ready to solve the PDE-constrained optimization problem with a targeted tolerance of 1e-5. In the following, we will use both Ipopt and DCI on our problem.","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"using NLPModelsIpopt\n\nstats_ipopt = ipopt(nlp, x0 = stats_trunk.solution, tol = 1e-5, print_level = 0)","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"\"Execution stats: first-order stationary\"","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"The problem was successfully solved, and we can extract the function evaluations from the stats.","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"stats_ipopt.counters","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"  Counters:\n             obj: ██████⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 9                 grad: ███████⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 10                cons: ████████████⋅⋅⋅⋅⋅⋅⋅⋅ 18    \n        cons_lin: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0             cons_nln: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 jcon: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n           jgrad: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                  jac: ███████⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 10             jac_lin: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n         jac_nln: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                jprod: ███████████████⋅⋅⋅⋅⋅ 22           jprod_lin: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n       jprod_nln: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0               jtprod: ████████████████████ 30          jtprod_lin: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n      jtprod_nln: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 hess: ██████⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 8                hprod: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n           jhess: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0               jhprod: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0             residual: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n    jac_residual: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0       jprod_residual: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0      jtprod_residual: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n   hess_residual: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0       jhess_residual: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0       hprod_residual: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"Reinitialize the counters before re-solving.","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"reset!(nlp);","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"NullLogger avoids printing iteration information.","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"using FletcherPenaltyNLPSolver, Logging\n\nstats_fps_solve = with_logger(NullLogger()) do\n  fps_solve(nlp, stats_trunk.solution, atol = 1e-5, rtol = 1e-5)\nend","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"\"Execution stats: first-order stationary\"","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"The problem was successfully solved, and we can extract the function evaluations from the stats.","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"stats_fps_solve.counters","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"  Counters:\n             obj: ██████⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 3                 grad: ████████⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 4                 cons: ████████⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 4     \n        cons_lin: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0             cons_nln: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 jcon: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n           jgrad: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                  jac: ██████████⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 5              jac_lin: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n         jac_nln: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                jprod: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0            jprod_lin: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n       jprod_nln: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0               jtprod: ██████████⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 5           jtprod_lin: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n      jtprod_nln: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 hess: ████████⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 4                hprod: ████████████████████ 10    \n           jhess: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0               jhprod: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0             residual: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n    jac_residual: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0       jprod_residual: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0      jtprod_residual: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n   hess_residual: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0       jhess_residual: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0       hprod_residual: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     \n","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"We now compare the two solvers with respect to the time spent,","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"stats_ipopt.elapsed_time, stats_fps_solve.elapsed_time","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"(39.725, 44.89158892631531)","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"and also check objective value, feasibility and dual feasibility of ipopt and fps_solve.","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"(stats_ipopt.objective, stats_ipopt.primal_feas, stats_ipopt.dual_feas),\n(stats_fps_solve.objective, stats_fps_solve.primal_feas, stats_fps_solve.dual_feas)","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"((0.005425026428348349, 1.1102230246251568e-18, 4.2724309076258577e-7), (0.005425025968573663, 2.2204460492503135e-18, 2.968652346957424e-7))","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"Overall FletcherPenaltyNLPSolver is doing great for solving large-scale optimization problems!","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"","category":"page"},{"location":"example/","page":"Large-scale example","title":"Large-scale example","text":"This page was generated using Literate.jl.","category":"page"}]
}
